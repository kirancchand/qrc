{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1d57ac59",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5ec4b95",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from qiskit import QuantumCircuit, QuantumRegister, ClassicalRegister, execute, Aer\n",
    "from qiskit.circuit import Parameter\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import recall_score, classification_report\n",
    "from sklearn.utils.class_weight import compute_class_weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "f9cdd466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_german_credit_data(file_path='statloggermancreditdata/german.data'):\n",
    "    \"\"\"\n",
    "    Load and preprocess the German Credit dataset.\n",
    "    \"\"\"\n",
    "    columns = [\n",
    "        'status', 'duration', 'credit_history', 'purpose', 'credit_amount',\n",
    "        'savings', 'employment', 'installment_rate', 'personal_status_sex',\n",
    "        'other_debtors', 'residence_since', 'property', 'age',\n",
    "        'other_installment_plans', 'housing', 'existing_credits',\n",
    "        'job', 'num_dependents', 'telephone', 'foreign_worker', 'class'\n",
    "    ]\n",
    "    \n",
    "    df = pd.read_csv(file_path, sep=' ', names=columns)\n",
    "    \n",
    "    numerical_cols = ['duration', 'credit_amount', 'installment_rate', \n",
    "                     'residence_since', 'age', 'existing_credits', \n",
    "                     'num_dependents']\n",
    "    categorical_cols = [col for col in df.columns if col not in numerical_cols]\n",
    "#     print(categorical_cols)\n",
    "    df_processed = df.copy()\n",
    "#     print(df_processed)\n",
    "    # Scale numerical features\n",
    "    scaler = StandardScaler()\n",
    "    df_processed[numerical_cols] = scaler.fit_transform(df_processed[numerical_cols])\n",
    "#     print(df_processed[numerical_cols])\n",
    "    # Encode categorical features\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        if col != 'class':\n",
    "            label_encoders[col] = LabelEncoder()\n",
    "            df_processed[col] = label_encoders[col].fit_transform(df_processed[col])\n",
    "#     print(df_processed)\n",
    "    # Convert class labels (1: Good, 2: Bad) to binary (0: Good, 1: Bad)\n",
    "    df_processed['class'] = df_processed['class'].map({1: 0, 2: 1})  # Reversed mapping for focus on bad credit\n",
    "    \n",
    "    X = df_processed.drop('class', axis=1).values\n",
    "#     print(X)\n",
    "    y = df_processed['class'].values\n",
    "#     print(scaler)\n",
    "    return X, y, scaler, label_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "dc9a775c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class QRCCreditRisk:\n",
    "    def __init__(self, n_qubits=6, reservoir_steps=7):  # Increased complexity\n",
    "        self.n_qubits = n_qubits\n",
    "        self.reservoir_steps = reservoir_steps\n",
    "        self.params = [Parameter(f'Î¸_{i}') for i in range(n_qubits * 2)]  # Doubled parameters\n",
    "        self.threshold = 0.3  # Lower threshold to favor positive class\n",
    "    \n",
    "    def create_reservoir_circuit(self, input_data):\n",
    "        qr = QuantumRegister(self.n_qubits, 'q')#6\n",
    "        cr = ClassicalRegister(self.n_qubits, 'c')#6\n",
    "        qc = QuantumCircuit(qr, cr)\n",
    "        print(input_data)\n",
    "#         print(input_data)\n",
    "        #input data is sample and it is each row value of X that values other than Result Class\n",
    "        # Enhanced input encoding \n",
    "        for i in range(self.n_qubits):\n",
    "            print(i % len(input_data))\n",
    "            print(input_data[i % len(input_data)])\n",
    "            print(input_data[i % len(input_data)] * np.pi)\n",
    "            qc.rx(input_data[i % len(input_data)] * np.pi, qr[i])\n",
    "            #len input_data is length of row,i should be from 1 to 6 and np.pi (ie .1 * pi gives a degree)is pi value for rotation with qr qc.rx(theta, qubit)\n",
    "            qc.rz(input_data[(i + 1) % len(input_data)] * np.pi, qr[i])\n",
    "            #similar to above\n",
    "#         display(qc.draw(output='mpl',reverse_bits=True))\n",
    "#         Create reservoir layers with enhanced connectivity\n",
    "        for step in range(self.reservoir_steps):\n",
    "            # All-to-all connectivity n_qubits = 6 so 6 operation actualy its 6-1\n",
    "            for i in range(self.n_qubits):\n",
    "                for j in range(i + 1, self.n_qubits):\n",
    "                    qc.cx(qr[i], qr[j])\n",
    "                qc.barrier()\n",
    "            \n",
    "            # Double rotation layers with parameters loops only 6\n",
    "            for i in range(self.n_qubits):\n",
    "                qc.ry(self.params[i], qr[i])\n",
    "                qc.rz(self.params[i + self.n_qubits], qr[i])\n",
    "                #both shoul dbe an angle value from current parameters\n",
    "            # Non-linear transformation\n",
    "            for i in range(self.n_qubits):\n",
    "                qc.rz(np.pi/2, qr[i])\n",
    "                #shouldbe an angle value from current parameters\n",
    "        qc.measure(qr, cr)\n",
    "#         display(qc.draw(output='mpl',reverse_bits=True))\n",
    "        return qc\n",
    "    \n",
    "    def get_reservoir_states(self, X, param_values):\n",
    "        reservoir_states = []\n",
    "        backend = Aer.get_backend('qasm_simulator')\n",
    "#         qc = self.create_reservoir_circuit(X[0])\n",
    "        for sample in X:\n",
    "            qc = self.create_reservoir_circuit(sample)\n",
    "#             must draw graph for each row value with 7 serial data bariier\n",
    "            param_dict = dict(zip(self.params, param_values))#[0_1,0_2],with random param_value,generate a key value pair\n",
    "            bound_qc = qc.bind_parameters(param_dict)\n",
    "            \n",
    "            job = execute(bound_qc, backend, shots=1000)\n",
    "            result = job.result()\n",
    "            counts = result.get_counts(bound_qc)\n",
    "            \n",
    "            state_vector = np.zeros(2**self.n_qubits)#create an array with 0 as value of size 2 raise to n_qubits(6)\n",
    "            for state, count in counts.items():\n",
    "                state_vector[int(state, 2)] = count/1000\n",
    "            #set value to each value of above array\n",
    "            reservoir_states.append(state_vector)\n",
    "            #add that value to reservoir states\n",
    "        return np.array(reservoir_states)\n",
    "    \n",
    "    def train(self, X, y, param_values=None):\n",
    "        #random param value from 360 degree,(pi) and size of self param ie 12\n",
    "        if param_values is None:\n",
    "            param_values = np.random.uniform(0, 2*np.pi, size=len(self.params))\n",
    "            #full rotation random value form 0 to 2*np.pi ie 6.3 seems to 360 * array value\n",
    "        # Calculate class weights\n",
    "        class_weights = compute_class_weight('balanced', classes=np.unique(y), y=y)\n",
    "        # y contain 0 and 1 only compute class weight create a weight for all y valuse and get clas_weight of 0 and 1\n",
    "#         print(\"class weight\",class_weights)\n",
    "        sample_weights = np.where(y == 1, class_weights[1], class_weights[0])\n",
    "#         print(\"sample_weights weight\",sample_weights) all weight where y=1 then this value is class_weight[1]\n",
    "        # Get reservoir states\n",
    "        reservoir_states = self.get_reservoir_states(X, param_values)\n",
    "        \n",
    "        # Weighted training\n",
    "        weighted_states = reservoir_states * sample_weights[:, np.newaxis]\n",
    "        weighted_y = y * sample_weights\n",
    "        \n",
    "        # Train readout layer with weighted samples\n",
    "        self.readout_weights = np.linalg.pinv(weighted_states) @ weighted_y\n",
    "        self.trained_param_values = param_values\n",
    "    \n",
    "    def predict(self, X):\n",
    "        reservoir_states = self.get_reservoir_states(X, self.trained_param_values)\n",
    "        predictions = reservoir_states @ self.readout_weights\n",
    "        return (predictions > self.threshold).astype(int)  # Using lower threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f7005997",
   "metadata": {},
   "outputs": [],
   "source": [
    "def optimize_threshold(model, X_val, y_val):\n",
    "    \"\"\"\n",
    "    Optimize threshold to maximize recall while maintaining reasonable precision\n",
    "    \"\"\"\n",
    "    reservoir_states = model.get_reservoir_states(X_val, model.trained_param_values)\n",
    "    raw_predictions = reservoir_states @ model.readout_weights\n",
    "    \n",
    "    best_recall = 0\n",
    "    best_threshold = 0.5\n",
    "    \n",
    "    for threshold in np.arange(0.1, 0.7, 0.05):\n",
    "        y_pred = (raw_predictions > threshold).astype(int)\n",
    "        recall = recall_score(y_val, y_pred)\n",
    "        \n",
    "        if recall > 0.5:  # We found a threshold that meets our goal\n",
    "            best_threshold = threshold\n",
    "            best_recall = recall\n",
    "            break\n",
    "            \n",
    "    return best_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "22fb3b60",
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (2237798003.py, line 18)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  Cell \u001b[0;32mIn[43], line 18\u001b[0;36m\u001b[0m\n\u001b[0;31m    n_qubits be changed to 20\u001b[0m\n\u001b[0m             ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "def main():\n",
    "    # Load and preprocess data\n",
    "    print(\"Loading and preprocessing German Credit dataset...\")\n",
    "    X, y, scaler, label_encoders = load_german_credit_data('statloggermancreditdata/german.data')\n",
    "#   y  is Class good or bad in 0,1\n",
    "#   X contains other data\n",
    "    # Split the data with validation set\n",
    "    X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "#     print(X_train)\n",
    "# x is value and y is result value here it is Class\n",
    "#   splitting for validation\n",
    "    X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "#     print(y_test)\n",
    "    # Initialize and train QRC model\n",
    "    print(\"Training QRC model...\")\n",
    "    qrc_model = QRCCreditRisk(n_qubits=6, reservoir_steps=7)\n",
    "    qrc_model.train(X_train, y_train)\n",
    "#     n_qubits be changed to 20\n",
    "    # Optimize threshold on validation set\n",
    "    print(\"Optimizing threshold...\")\n",
    "    best_threshold = optimize_threshold(qrc_model, X_val, y_val)\n",
    "    qrc_model.threshold = best_threshold\n",
    "    print(f\"Optimal threshold: {best_threshold:.3f}\")\n",
    "    \n",
    "    # Make predictions on test set\n",
    "    print(\"Making predictions...\")\n",
    "    y_pred = qrc_model.predict(X_test)\n",
    "    \n",
    "    # Evaluate results\n",
    "    print(\"\\nModel Performance:\")\n",
    "    print(\"\\nClassification Report:\")\n",
    "#     print(classification_report(y_test, y_pred))\n",
    "    \n",
    "    # Print recall specifically\n",
    "    recall = recall_score(y_test, y_pred)\n",
    "    print(f\"\\nRecall for bad credit risk: {recall:.3f}\")\n",
    "    \n",
    "    if recall > 0.5:\n",
    "        print(\"â Achieved recall goal (> 0.5)\")\n",
    "    else:\n",
    "        print(\"â Did not achieve recall goal (> 0.5)\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af7d27c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
